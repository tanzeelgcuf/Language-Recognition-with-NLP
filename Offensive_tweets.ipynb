{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Offensive_tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5EkrzM-1_JU"
      },
      "source": [
        "#Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5m6vPje2hiy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09f7d3cc-88a7-4a7b-e8ba-775406b76ac5"
      },
      "source": [
        "train_directory = \"datasets/training/offenseval-training-v1.tsv\"\n",
        "print(\"Reading Dataset...\")\n",
        "train_data = pd.read_csv(train_directory, sep='\\t', header=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading Dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucASsaD24HvU"
      },
      "source": [
        "tweets = train_data[[\"tweet\"]]\n",
        "subtask_a_labels = train_data[[\"subtask_a\"]]\n",
        "subtask_b_labels = train_data.query(\"subtask_a == 'OFF'\")[[\"subtask_b\"]]\n",
        "subtask_c_labels = train_data.query(\"subtask_b == 'TIN'\")[[\"subtask_c\"]]\n",
        "\n",
        "clean_tweets = copy.deepcopy(tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3FKc2Kp4MxS"
      },
      "source": [
        "##PREPROCESSING##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJHU2cRi5SH1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7208c3c9-7fc1-4862-e923-89db2eeea598"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt', 'stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to stopwords...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7qm0EYh5bhB"
      },
      "source": [
        "def take_data_to_shower(tweet):\n",
        "    noises = ['URL', '@USER', '\\'ve', 'n\\'t', '\\'s', '\\'m']\n",
        "\n",
        "    for noise in noises:\n",
        "        tweet = tweet.replace(noise, '')\n",
        "\n",
        "    return re.sub(r'[^a-zA-Z]', ' ', tweet)\n",
        "\n",
        "\n",
        "def tokenize(tweet):\n",
        "    lower_tweet = tweet.lower()\n",
        "    return word_tokenize(lower_tweet)\n",
        "\n",
        "\n",
        "def remove_stop_words(tokens):\n",
        "    clean_tokens = []\n",
        "    stopWords = set(stopwords.words('english'))\n",
        "    for token in tokens:\n",
        "        if token not in stopWords:\n",
        "            if token.replace(' ', '') != '':\n",
        "                if len(token) > 1:\n",
        "                    clean_tokens.append(token)\n",
        "    return clean_tokens\n",
        "\n",
        "\n",
        "def stem_and_lem(tokens):\n",
        "    clean_tokens = []\n",
        "    for token in tokens:\n",
        "        token = wordnet_lemmatizer.lemmatize(token)\n",
        "        token = lancaster_stemmer.stem(token)\n",
        "        if len(token) > 1:\n",
        "            clean_tokens.append(token)\n",
        "    return clean_tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSwKKcS35gmW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "d7b0f0e6-2bf1-48fe-d95d-6ab2e74d5573"
      },
      "source": [
        "tqdm.pandas(desc=\"Cleaning Data Phase I...\")\n",
        "clean_tweets['tweet'] = tweets['tweet'].progress_apply(take_data_to_shower)\n",
        "\n",
        "tqdm.pandas(desc=\"Tokenizing Data...\")\n",
        "clean_tweets['tokens'] = clean_tweets['tweet'].progress_apply(tokenize)\n",
        "\n",
        "tqdm.pandas(desc=\"Cleaning Data Phase II...\")\n",
        "clean_tweets['tokens'] = clean_tweets['tokens'].progress_apply(remove_stop_words)\n",
        "\n",
        "tqdm.pandas(desc=\"Stemming And Lemmatizing\")\n",
        "clean_tweets['tokens'] = clean_tweets['tokens'].progress_apply(stem_and_lem)\n",
        "\n",
        "text_vector = clean_tweets['tokens'].tolist()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cleaning Data Phase I...: 100%|██████████| 13240/13240 [00:00<00:00, 90838.52it/s]\n",
            "Tokenizing Data...: 100%|██████████| 13240/13240 [00:02<00:00, 5726.47it/s]\n",
            "Cleaning Data Phase II...: 100%|██████████| 13240/13240 [00:02<00:00, 5410.97it/s]\n",
            "Stemming And Lemmatizing: 100%|██████████| 13240/13240 [00:05<00:00, 2476.73it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y2fN2MC8Ara"
      },
      "source": [
        "##EMBEDDING##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoVtfyxb5lp3"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def tfid(text_vector):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    untokenized_data =[' '.join(tweet) for tweet in tqdm(text_vector, \"Vectorizing...\")]\n",
        "    vectorizer = vectorizer.fit(untokenized_data)\n",
        "    vectors = vectorizer.transform(untokenized_data).toarray()\n",
        "    return vectors\n",
        "  \n",
        "def get_vectors(vectors, labels, keyword):\n",
        "    if len(vectors) != len(labels):\n",
        "        print(\"Unmatching sizes!\")\n",
        "        return\n",
        "    result = list()\n",
        "    for vector, label in zip(vectors, labels):\n",
        "        if label == keyword:\n",
        "            result.append(vector)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuA8n1dt7VJe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6a9a0365-8a2e-4ac9-dc4f-28083de3f0ab"
      },
      "source": [
        "vectors_a = tfid(text_vector) # Numerical Vectors A\n",
        "labels_a = subtask_a_labels['subtask_a'].values.tolist() # Subtask A Labels\n",
        "\n",
        "vectors_b = get_vectors(vectors_a, labels_a, \"OFF\") # Numerical Vectors B\n",
        "labels_b = subtask_b_labels['subtask_b'].values.tolist() # Subtask B Labels\n",
        "\n",
        "vectors_c = get_vectors(vectors_b, labels_b, \"TIN\") # Numerical Vectors C\n",
        "labels_c = subtask_c_labels['subtask_c'].values.tolist() # Subtask C Labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorizing...: 100%|██████████| 13240/13240 [00:00<00:00, 687301.48it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xxecoX_7dWS"
      },
      "source": [
        "##CLASSIFING##"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vllyKsR475YC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def classify(vectors, labels, type=\"DT\"):\n",
        "    # Random Splitting With Ratio 3 : 1\n",
        "    train_vectors, test_vectors, train_labels, test_labels = train_test_split(vectors, labels, test_size=0.25)\n",
        "\n",
        "    # Initialize Model\n",
        "    classifier = None\n",
        "    if(type==\"MNB\"):\n",
        "        classifier = MultinomialNB(alpha=0.7)\n",
        "        classifier.fit(train_vectors, train_labels)\n",
        "    elif(type==\"KNN\"):\n",
        "        classifier = KNeighborsClassifier(n_jobs=4)\n",
        "        params = {'n_neighbors': [3,5,7,9], 'weights':['uniform', 'distance']}\n",
        "        classifier = GridSearchCV(classifier, params, cv=3, n_jobs=4)\n",
        "        classifier.fit(train_vectors, train_labels)\n",
        "        classifier = classifier.best_estimator_\n",
        "    elif(type==\"SVM\"):\n",
        "        classifier = SVC()\n",
        "        classifier = GridSearchCV(classifier, {'C':[0.001, 0.01, 0.1, 1, 10]}, cv=3, n_jobs=4)\n",
        "        classifier.fit(train_vectors, train_labels)\n",
        "        classifier = classifier.best_estimator_\n",
        "    elif(type==\"DT\"):\n",
        "        classifier = DecisionTreeClassifier(max_depth=800, min_samples_split=5)\n",
        "        params = {'criterion':['gini','entropy']}\n",
        "        classifier = GridSearchCV(classifier, params, cv=3, n_jobs=4)\n",
        "        classifier.fit(train_vectors, train_labels)\n",
        "        classifier = classifier.best_estimator_\n",
        "    elif(type==\"RF\"):\n",
        "        classifier = RandomForestClassifier(max_depth=800, min_samples_split=5)\n",
        "        params = {'n_estimators': [n for n in range(50,200,50)], 'criterion':['gini','entropy'], }\n",
        "        classifier = GridSearchCV(classifier, params, cv=3, n_jobs=4)\n",
        "        classifier.fit(train_vectors, train_labels)\n",
        "        classifier = classifier.best_estimator_\n",
        "    elif(type==\"LR\"):\n",
        "        classifier = LogisticRegression(multi_class='auto', solver='newton-cg',)\n",
        "        classifier = GridSearchCV(classifier, {\"C\":np.logspace(-3,3,7), \"penalty\":[\"l2\"]}, cv=3, n_jobs=4)\n",
        "        classifier.fit(train_vectors, train_labels)\n",
        "        classifier = classifier.best_estimator_\n",
        "    else:\n",
        "        print(\"Wrong Classifier Type!\")\n",
        "        return\n",
        "\n",
        "    accuracy = accuracy_score(train_labels, classifier.predict(train_vectors))\n",
        "    print(\"Training Accuracy:\", accuracy)\n",
        "    test_predictions = classifier.predict(test_vectors)\n",
        "    accuracy = accuracy_score(test_labels, test_predictions)\n",
        "    print(\"Test Accuracy:\", accuracy)\n",
        "    print(\"Confusion Matrix:\", )\n",
        "    print(confusion_matrix(test_labels, test_predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUc62OmA8KrF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "af7faf87-d5ff-4c7d-987a-c35c0c3839c2"
      },
      "source": [
        "print(\"\\nBuilding Model Subtask A...\")\n",
        "classify(vectors_a[:], labels_a[:], \"SVM\") # {MNB, KNN, SVM, DT, RF, LR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Building Model Subtask A...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.66\n",
            "Test Accuracy: 0.664\n",
            "Confusion Matrix:\n",
            "[[166   0]\n",
            " [ 84   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASbewYhr8Yha",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "da461e12-13c6-4c7d-f090-9c37c5eb3bac"
      },
      "source": [
        "print(\"\\nBuilding Model Subtask B...\")\n",
        "classify(vectors_b[:], labels_b[:], \"SVM\") # {MNB, KNN, SVM, DT, RF, LR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Building Model Subtask B...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.8773333333333333\n",
            "Test Accuracy: 0.884\n",
            "Confusion Matrix:\n",
            "[[221   0]\n",
            " [ 29   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAF7Vz3nlWj8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "3aa22dd2-07e6-4768-ec44-80d18b697687"
      },
      "source": [
        "print(\"\\nBuilding Model Subtask C...\")\n",
        "classify(vectors_c[:], labels_c[:], \"SVM\") # {MNB, KNN, SVM, DT, RF, LR}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Building Model Subtask C...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.628\n",
            "Test Accuracy: 0.604\n",
            "Confusion Matrix:\n",
            "[[  0  70   0]\n",
            " [  0 151   0]\n",
            " [  0  29   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfhWGl8zCFt3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}